{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import with_statement\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, open an ssh tunnel to the CatSim database hosted by the University of Washington.  Open a terminal window and type\n",
    "\n",
    "```\n",
    "ssh -L 51433:fatboy.phys.washington.edu:1433 simsuser@gateway.astro.washington.edu\n",
    "```\n",
    "\n",
    "There is some configuration that you will have to do to make sure this works.  Instructions are here:\n",
    "\n",
    "https://confluence.lsstcorp.org/display/SIM/Accessing+the+UW+CATSIM+Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to specify the download a database of OpSim-simulated pointings from\n",
    "\n",
    "https://www.lsst.org/scientists/simulations/opsim/opsim-surveys-data-directory\n",
    "\n",
    "and specify its location with the ```opsimdb``` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "opsimdb = os.path.join(\"/Users\",\"danielsf\",\"physics\")\n",
    "opsimdb = os.path.join(opsimdb, \"lsst_150412\", \"Development\", \"garage\")\n",
    "opsimdb = os.path.join(opsimdb, \"OpSimData\", \"kraken_1042_sqlite.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connections to the CatSim database of celestial objects are handled via the classes stored in ```lsst.sims.catUtils.baseCatalogModels```.  To see what's available, you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lsst.sims.catUtils.baseCatalogModels as baseCatalogModels\n",
    "\n",
    "dir(baseCatalogModels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the confluence page\n",
    "\n",
    "https://confluence.lsstcorp.org/display/SIM/Database+Schema\n",
    "\n",
    "For this tutorial, will instantiate a connection to the table of RRLyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lsst.sims.catUtils.baseCatalogModels import RRLyStarObj\n",
    "stardb = RRLyStarObj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a LightCurveGenerator, connecting it to both our database of celestial objects and our database of simulated pointings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lsst.sims.catUtils.utils import StellarLightCurveGenerator\n",
    "lc_gen = StellarLightCurveGenerator(stardb, opsimdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us query our database of pointings for all of the pointings in a range of RA and Dec and a set of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raRange = (60.0, 65.0)\n",
    "decRange = (-15.0, -10.0)\n",
    "bandpass = ('g', 'r', 'i')\n",
    "pointings = lc_gen.get_pointings(raRange, decRange, bandpass=bandpass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pointings` is now a 2-D list.  Each row of the list is a set of pointings (represented by instantiations of the `ObservationMetaData` class) at different dates and through different filters but centered on the same patch of sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(pointings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the `LightCurveGenerator` to extract the light curves of all of the objects in our selected pointings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc_dict, truth_dict = lc_gen.light_curves_from_pointings(pointings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze one of these light curves using the `gatspy` time series analysis package described here\n",
    "\n",
    "https://jakevdp.github.io/blog/2015/06/13/lomb-scargle-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc = lc_dict[853673991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better or worse, variability in CatSim is represented as a json-encoded dict that points to a light curve which lives in the lsst `sims_sed_library` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print truth_dict[853673991]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the `1981625_per.txt` light curve file, we see that this corresponds to an RR Lyra with a period of 0.485873 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first just plot one of our light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.errorbar(lc['r']['mjd'], lc['r']['mag'], lc['r']['error'],\n",
    "            fmt='', linestyle='None')\n",
    "ax.set(xlabel='MJD', ylabel='r-band magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's construct a Lomb-Scargle periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gatspy.periodic import LombScargleFast\n",
    "model = LombScargleFast().fit(lc['r']['mjd'], lc['r']['mag'],\n",
    "                              lc['r']['error'])\n",
    "periods, power = model.periodogram_auto(nyquist_factor=100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(periods, power)\n",
    "ax.set(xlim=(0.0001, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the highest-power period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.period_range = (0.1, 1.4)\n",
    "best_period = model.best_period\n",
    "print best_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is very close to our expected period of 0.485873 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's analyze several light curves.  We will start by scraping the light curve files in `sims_sed_library` to get their periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lsst.utils import getPackageDir\n",
    "import time\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "reference_dict = {}\n",
    "truth_dir = os.path.join(getPackageDir('sims_sed_library'), 'rrly_lc')\n",
    "\n",
    "rrab_dir = os.path.join(truth_dir, 'RRab')\n",
    "rrc_dir = os.path.join(truth_dir, 'RRc')\n",
    "\n",
    "for file_name in os.listdir(rrab_dir):\n",
    "    if 'per' in file_name:\n",
    "        full_name = os.path.join(rrab_dir, file_name)\n",
    "        with open(full_name, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                vv = line.split()\n",
    "                if vv[1] == 'Period':\n",
    "                    reference_dict['rrly_lc/RRab/'+file_name] = float(vv[3])\n",
    "                    break\n",
    "\n",
    "for file_name in os.listdir(rrc_dir):\n",
    "    if 'per' in file_name:\n",
    "        full_name = os.path.join(rrc_dir, file_name)\n",
    "        with open(full_name, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                vv = line.split()\n",
    "                if vv[1] == 'Period':\n",
    "                    reference_dict['rrly_lc/RRc/'+file_name] = float(vv[3])\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop through the first 10 light curves and calculate their highest-power periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "true_period = []\n",
    "found_period = []\n",
    "\n",
    "for kk in lc_dict.keys()[:10]:\n",
    "    lc_obj = lc_dict[kk]\n",
    "    truth = json.loads(truth_dict[kk])\n",
    "    file_name = truth['pars']['filename']\n",
    "    for ff in lc_obj.keys()[:1]:\n",
    "        lc = lc_obj[ff]\n",
    "\n",
    "        model = LombScargleFast().fit(lc['mjd'], lc['mag'],\n",
    "                                      lc['error'])\n",
    "        model.optimizer.period_range = (0.1, 1.4)\n",
    "        best_period = model.best_period\n",
    "        true_period.append(reference_dict[file_name])\n",
    "        found_period.append(best_period)\n",
    "\n",
    "true_period = np.array(true_period)\n",
    "found_peroid = np.array(found_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the true periods in our light curve files, we find very good agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tt, ff in zip(true_period, found_period):\n",
    "    print tt, ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generating your own cadence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work above used an OpSim-generated database of observations to define the observing cadence in the light curves.  If you want to experiment with your own cadence, you will need to mock the OpSim database.\n",
    "\n",
    "The relevant table is the `Summary` table, whose schema can be found here\n",
    "\n",
    "https://www.lsst.org/scientists/simulations/opsim/summary-table-column-descriptions-v335\n",
    "\n",
    "Below: we will generate a somewhat random set of observations and construct a sqlite database that contains the relevant columns of the `Summary` table and use that as our cadence for light curve generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lsst.sims.utils import ObservationMetaData, solarRaDec\n",
    "from lsst.sims.utils import altAzPaFromRaDec\n",
    "\n",
    "import warnings\n",
    "\n",
    "# suppress some warnings raised by astropy.time when you\n",
    "# calculate the relationship between UT1 and UTC in the future\n",
    "warnings.filterwarnings('ignore',message=\".*UT1-UTC.*\")\n",
    "\n",
    "rng = np.random.RandomState(87)\n",
    "\n",
    "# pick a point on the sky to center our observations\n",
    "field_ra = 112.0\n",
    "field_dec = -31.0\n",
    "\n",
    "# generate a random sample of MJDs\n",
    "mjd_candidates = rng.random_sample(1000)*3653.0+59580.0\n",
    "mjd_candidates.sort()\n",
    "\n",
    "obs_list = [ObservationMetaData(mjd=mm) for mm in mjd_candidates]\n",
    "\n",
    "# calculate the altitude and azimuth of the sun at those MJDs\n",
    "solar_alt = []\n",
    "solar_az = []\n",
    "for obs in obs_list:\n",
    "    rr, dd = solarRaDec(obs.mjd)\n",
    "    alt, az, pp = altAzPaFromRaDec(rr, dd, obs)\n",
    "    solar_alt.append(alt)\n",
    "    solar_az.append(az)  \n",
    "\n",
    "print \"getting solar ra dec took \",time.time()-t_start\n",
    "\n",
    "# select only those MJDs where the sun is at least 10 degrees below\n",
    "# the horizon\n",
    "solar_alt = np.array(solar_alt)\n",
    "solar_az = np.array(solar_az)\n",
    "\n",
    "dexes_sundown = np.where(solar_alt<-10.0)\n",
    "print len(dexes_sundown[0])\n",
    "\n",
    "n_time = len(dexes_sundown[0])\n",
    "\n",
    "# further select MJDs where our field is more thatn 45 degrees\n",
    "# above the horizon\n",
    "obs_list = np.array(obs_list)[dexes_sundown]\n",
    "alt_list = []\n",
    "az_list = []\n",
    "for obs in obs_list:\n",
    "    alt, az, pp = altAzPaFromRaDec(field_ra, field_dec, obs)\n",
    "    alt_list.append(alt)\n",
    "    az_list.append(az)\n",
    "\n",
    "alt_list = np.array(alt_list)\n",
    "dexes = np.where(alt_list>45.0)\n",
    "\n",
    "mjd_list = np.array([obs.mjd.TAI for obs in obs_list[dexes]])\n",
    "airmass_list = np.array([1.0/np.cos(0.5*np.pi-alt)\n",
    "                         for alt in np.radians(alt_list[dexes])])\n",
    "print len(mjd_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load throughputs for the LSST bandpasses and site atmosphere at different airmasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "from lsst.utils import getPackageDir\n",
    "from lsst.sims.photUtils import BandpassDict\n",
    "atmos_dir = os.path.join(getPackageDir('throughputs'), 'atmos')\n",
    "bp_dict = {}\n",
    "hw_dict = {}\n",
    "for airmass in np.arange(1.0, 2.6, 0.1):\n",
    "    am_int = int(10*airmass)\n",
    "    atmos_name = os.path.join(atmos_dir, 'atmos_%d.dat' % am_int)\n",
    "    bp, hw = \\\n",
    "    BandpassDict.loadBandpassesFromFiles(atmoTransmission=atmos_name)\n",
    "    bp_dict[am_int] = bp\n",
    "    hw_dict[am_int] = hw\n",
    "print \"that took \",time.time()-t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random seeing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fwhm_eff_list = rng.random_sample(len(mjd_list))*0.1+0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `sims_skybrightness` package to calculate the sky brightness and 5-sigma limiting magnitude at these MJDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*UT1-UTC.*')\n",
    "\n",
    "from lsst.sims.skybrightness import SkyModel\n",
    "model = SkyModel(lowerAtm=True, upperAtm=True, scatteredStar=True)\n",
    "\n",
    "from lsst.sims.utils import altAzPaFromRaDec\n",
    "from lsst.sims.photUtils import Sed, calcM5, PhotometricParameters\n",
    "\n",
    "bp_name_options = np.array(['g', 'r', 'i'])\n",
    "bp_name_list = bp_name_options[rng.random_integers(0,2,\n",
    "                                len(mjd_list))]\n",
    "photParams = PhotometricParameters()\n",
    "\n",
    "m5_list = []\n",
    "sky_brightness_list = []\n",
    "\n",
    "for mjd, airmass, fwhm, bp_name in \\\n",
    "    zip(mjd_list, airmass_list,\n",
    "        fwhm_eff_list, bp_name_list):\n",
    "        \n",
    "    model.setRaDecMjd(field_ra, field_dec, mjd, degrees=True)\n",
    "    wv, fl = model.returnWaveSpec()\n",
    "    ss = Sed(wavelen=wv, flambda=fl[0])\n",
    "    am_int = int(10*airmass)\n",
    "    m5 = calcM5(ss,\n",
    "                bp_dict[am_int][bp_name],\n",
    "                hw_dict[am_int][bp_name],\n",
    "                photParams, FWHMeff=fwhm)\n",
    "    m5_list.append(m5)\n",
    "    sky_brightness_list.append(ss.calcMag(bp_dict[am_int][bp_name]))\n",
    "\n",
    "print \"that took \",time.time()-t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m5_list = np.array(m5_list)\n",
    "sky_brightness_list = np.array(sky_brightness_list)\n",
    "print sky_brightness_list.min()\n",
    "print sky_brightness_list.max()\n",
    "print field_ra\n",
    "print field_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sqlite database using the mock observation data we have just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db_file_name = \"example_test_cadence.db\"\n",
    "if os.path.exists(db_file_name):\n",
    "    os.unlink(db_file_name)\n",
    "conn = sqlite3.connect(db_file_name)\n",
    "cc = conn.cursor()\n",
    "cc.execute('''CREATE TABLE Summary\n",
    "              (fieldRA float, fieldDec float, expMJD float,\n",
    "              filter text, FWHMeff float, fiveSigmaDepth float,\n",
    "              filtSkyBrightness float)''')\n",
    "\n",
    "for mjd, bp, fwhm, m5, bright in \\\n",
    "zip(mjd_list, bp_name_list, fwhm_eff_list, m5_list, sky_brightness_list):\n",
    "    cmd = '''INSERT INTO Summary VALUES(%.5f, %.5f, %.3f, '%s', %.5f, %.5f, %.5f)''' \\\n",
    "    % (np.radians(field_ra), np.radians(field_dec), mjd, bp, fwhm, m5,\n",
    "      bright)\n",
    "    cc.execute(cmd)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate light curves using our mock pointing database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = StellarLightCurveGenerator(stardb, db_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pointings = gen.get_pointings((field_ra-1.0, field_ra+1.0),\n",
    "                              (field_dec-1.0, field_dec+1.0),\n",
    "                              bandpass=('g','r','i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pointings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pointings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc, truth = gen.light_curves_from_pointings(pointings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
